{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем скачанный классификатор токсичности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimdi-y/.local/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.6) or chardet (2.3.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "  \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"trained_roberta/\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"trained_roberta/\").cuda()\n",
    "\n",
    "TOXIC_CLASS=-1\n",
    "TOKENIZATION_TYPE='sentencepiece'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже функции для применения классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import softmax, sigmoid\n",
    "import numpy as np\n",
    "\n",
    "def logits_to_toxic_probas(logits):\n",
    "    if logits.shape[-1] > 1:\n",
    "        activation = lambda x: softmax(x, -1)\n",
    "    else:\n",
    "        activation = sigmoid\n",
    "    return activation(logits)[:, TOXIC_CLASS].cpu().detach().numpy()\n",
    "\n",
    "\n",
    "def is_word_start(token):\n",
    "    if TOKENIZATION_TYPE == 'sentencepiece':\n",
    "        return token.startswith('▁')\n",
    "    if TOKENIZATION_TYPE == 'bert':\n",
    "        return not token.startswith('##')\n",
    "    raise ValueError(\"Unknown tokenization type\")\n",
    "\n",
    "\n",
    "def normalize(sentence, max_tokens_per_word=20):\n",
    "    sentence = ''.join(map(lambda c: c if c.isalpha() else ' ', sentence.lower()))\n",
    "    ids = tokenizer(sentence)['input_ids']\n",
    "    tokens = tokenizer.convert_ids_to_tokens(ids)[1:-1]\n",
    "    \n",
    "    result = []\n",
    "    num_continuation_tokens = 0\n",
    "    for token in tokens:\n",
    "        if not is_word_start(token):\n",
    "            num_continuation_tokens += 1\n",
    "            if num_continuation_tokens < max_tokens_per_word:\n",
    "                result.append(token.lstrip('#▁'))\n",
    "        else:\n",
    "            num_continuation_tokens = 0\n",
    "            result.extend([' ', token.lstrip('▁#')])\n",
    "    \n",
    "    return ''.join(result).strip()\n",
    "\n",
    "def iterate_batches(data, batch_size=40):\n",
    "    batch = []\n",
    "    for x in data:\n",
    "        batch.append(x)\n",
    "        if len(batch) >= batch_size:\n",
    "            yield batch\n",
    "            batch = []\n",
    "    if len(batch) > 0:\n",
    "        yield batch\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "def predict_toxicity(sentences, batch_size=5, threshold=0.5, return_scores=False, verbose=True, device='cuda'):\n",
    "    results = []\n",
    "    tqdm_fn = tqdm if verbose else lambda x, total: x\n",
    "    for batch in tqdm_fn(iterate_batches(sentences, batch_size), total=np.ceil(len(sentences) / batch_size)):\n",
    "        normlized = [normalize(sent, max_tokens_per_word=5) for sent in batch]\n",
    "        tokenized = tokenizer(normlized, return_tensors='pt', padding=True, max_length=512, truncation=True)\n",
    "        \n",
    "        logits = model.to(device)(**{key: val.to(device) for key, val in tokenized.items()}).logits\n",
    "        preds = logits_to_toxic_probas(logits)\n",
    "        if not return_scores:\n",
    "            preds = preds >= threshold\n",
    "        results.extend(preds)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем тестовый набор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "with open('public_testset.short.txt', 'rt') as f:\n",
    "    for line in f:\n",
    "        texts.append(normalize(line)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисляем токсичность отдельных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253b4b8ac15a4abdbaef313808ac2932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "words = set()\n",
    "for text in texts:\n",
    "    words.update(text.split())\n",
    "words = sorted(words)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    word_toxicities = predict_toxicity(words, batch_size=100, return_scores=True)\n",
    "    \n",
    "toxicity = dict(zip(words, word_toxicities))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже читаем эмбеддинги слов и описываем функции их обработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "stemmer = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_file = np.load('embeddings_with_lemmas.npz', allow_pickle=True)\n",
    "embs_vectors = embs_file['vectors']\n",
    "embs_vectors_normed = embs_vectors / np.linalg.norm(embs_vectors, axis=1, keepdims=True)\n",
    "embs_voc = embs_file['voc'].item()\n",
    "\n",
    "embs_voc_by_id = [None for i in range(len(embs_vectors))]\n",
    "for word, idx in embs_voc.items():\n",
    "    if embs_voc_by_id[idx] is None:\n",
    "        embs_voc_by_id[idx] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v_indicies(a):\n",
    "    res = []\n",
    "    if isinstance(a, str):\n",
    "        a = a.split()\n",
    "    for w in a:\n",
    "        if w in embs_voc:\n",
    "            res.append(embs_voc[w])\n",
    "        else:\n",
    "            lemma = stemmer.lemmatize(w)[0]\n",
    "            res.append(embs_voc.get(lemma, None))\n",
    "    return res\n",
    "\n",
    "def calc_embs(words):\n",
    "    words = ' '.join(map(normalize, words))\n",
    "    inds = get_w2v_indicies(words)\n",
    "    return [None if i is None else embs_vectors[i] for i in inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сложим эмбеддинги нетоксичных слов в kd-дерево, чтобы можно было близко искать ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nontoxic_emb_inds = [ind for word, ind in embs_voc.items() if toxicity.get(word, 1.0) <= 0.5]\n",
    "embs_vectors_normed_nontoxic = embs_vectors_normed[nontoxic_emb_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "embs_tree = KDTree(embs_vectors_normed_nontoxic, leaf_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция находит самое близкое нетоксичное слово по предпосчитанным эмбеддингам слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache()\n",
    "def find_closest_nontoxic(word, threshold=0.5, allow_self=False):\n",
    "    if toxicity.get(word, 1.0) <= threshold:\n",
    "        return word\n",
    "    \n",
    "    if word not in toxicity and word not in embs_voc:\n",
    "        return None\n",
    "    \n",
    "    threshold = min(toxicity.get(word, threshold), threshold)\n",
    "    word = normalize(word)\n",
    "    word_emb = calc_embs([word])\n",
    "    if word_emb is None or word_emb[0] is None:\n",
    "        return None\n",
    "    \n",
    "    for i in embs_tree.query(word_emb)[1][0]:\n",
    "        other_word = embs_voc_by_id[nontoxic_emb_inds[i]]\n",
    "        if (other_word != word or allow_self) and toxicity.get(other_word, 1.0) <= threshold:\n",
    "            return other_word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменяем токсичные слова на ближайшие по эмбеддингам не-токсичные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detox(line):\n",
    "    words = normalize(line).split()\n",
    "    fixed_words = [find_closest_nontoxic(word, allow_self=True) or '' for word in words]\n",
    "    return ' '.join(fixed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc176422c4a48a9b06a7600f8907516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fixed_texts = list(map(detox, tqdm(texts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "запишем результат в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('baseline_fixed.txt', 'wt') as f:\n",
    "    for text in fixed_texts:\n",
    "        print(text, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скор, если никак не изменять комментарии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dimdi-y/.local/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.6) or chardet (2.3.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Loading tokenizer\n",
      "Loading model\n",
      "Loading texts\n",
      "Loading embeddings\n",
      "Scoring\n",
      " 18%|███████▎                                | 92/500.0 [00:03<00:15, 26.92it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|███████████████████████████████████████| 500/500.0 [00:20<00:00, 24.07it/s]\n",
      "2500it [00:12, 202.25it/s]\n",
      "28.08\n"
     ]
    }
   ],
   "source": [
    "!python3.7 score.py public_testset.short.txt public_testset.short.txt  --embeddings embeddings_with_lemmas.npz --model ./trained_roberta/ --device cuda --score -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скор бейзлайна:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dimdi-y/.local/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.6) or chardet (2.3.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Loading tokenizer\n",
      "Loading model\n",
      "Loading texts\n",
      "Loading embeddings\n",
      "Scoring\n",
      " 24%|█████████▏                             | 118/500.0 [00:04<00:22, 17.10it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|███████████████████████████████████████| 500/500.0 [00:20<00:00, 24.98it/s]\n",
      "2500it [00:28, 88.25it/s] \n",
      "41.06\n"
     ]
    }
   ],
   "source": [
    "!python3.7 score.py public_testset.short.txt baseline_fixed.txt  --embeddings embeddings_with_lemmas.npz --model ./trained_roberta/ --device cuda --score -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним данные для бейзлайна online-задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p online_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open('./online_baseline/data.pkl', 'wb') as f:\n",
    "    pkl.dump(toxicity, f)\n",
    "    pkl.dump(nontoxic_emb_inds, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
